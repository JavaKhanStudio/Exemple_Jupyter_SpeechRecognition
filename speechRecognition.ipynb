{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üé§ Reconnaissance Vocale Hors Ligne - Guide d'Utilisation\n",
    "\n",
    "## üìã Comment utiliser ce notebook\n",
    "\n",
    "### √âtape 1Ô∏è‚É£ : Installation et Imports (Cellule 1)\n",
    "Ex√©cutez cette cellule pour importer les biblioth√®ques n√©cessaires.\n",
    "Si les packages ne sont pas install√©s, d√©commentez la ligne `!pip install ...` et ex√©cutez-la d'abord.\n",
    "\n",
    "### √âtape 2Ô∏è‚É£ : Configuration (Cellule 2)\n",
    "Ex√©cutez cette cellule pour charger les configurations des mod√®les disponibles.\n",
    "\n",
    "### √âtape 3Ô∏è‚É£ : S√©lection du Moteur (Cellule 3) ‚ö†Ô∏è **IMPORTANT**\n",
    "**C'est ici que vous choisissez votre moteur de reconnaissance !**\n",
    "- S√©lectionnez **Sphinx** (int√©gr√©, aucun t√©l√©chargement) ou **Vosk** (meilleure pr√©cision)\n",
    "- Si vous choisissez Vosk, s√©lectionnez le mod√®le de langue\n",
    "- Cliquez sur \"Apply & Load Model\"\n",
    "- **Attendez que le mod√®le se charge avant de continuer**\n",
    "\n",
    "### √âtape 4Ô∏è‚É£ : Fonctions Utilitaires (Cellule 4)\n",
    "Ex√©cutez cette cellule pour charger les fonctions de reconnaissance.\n",
    "\n",
    "### √âtape 5Ô∏è‚É£ : V√©rifier vos Microphones (Cellule 5)\n",
    "Optionnel - liste tous vos microphones disponibles.\n",
    "\n",
    "### √âtape 6Ô∏è‚É£ : Test Rapide (Cellule 6)\n",
    "D√©commentez `test_single_recognition()` pour tester avec une seule phrase.\n",
    "\n",
    "### √âtape 7Ô∏è‚É£ : √âcoute Continue (Cellule 7)\n",
    "D√©commentez `start_continuous_listening()` pour une reconnaissance en continu.\n",
    "**Appuyez sur le bouton stop (‚ñ†) pour arr√™ter.**\n",
    "\n",
    "### √âtape 8Ô∏è‚É£ : Reconnaissance depuis un Fichier (Cellule 8)\n",
    "Pour transcrire un fichier audio existant (WAV, AIFF, FLAC).\n",
    "\n",
    "### √âtape 9Ô∏è‚É£ : Cr√©er un Enregistrement de Test (Cellule 9)\n",
    "Pour cr√©er un fichier audio de test.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ D√©marrage Rapide\n",
    "1. Ex√©cutez les cellules 1 ‚Üí 2 ‚Üí 3 ‚Üí 4\n",
    "2. Dans la cellule 3, choisissez votre moteur et cliquez sur \"Apply & Load Model\"\n",
    "3. Choisissez une cellule d'utilisation (6, 7, 8, ou 9) et d√©commentez la fonction\n",
    "4. Ex√©cutez et parlez !\n",
    "\n",
    "---"
   ],
   "id": "235375ee6cf139ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 1: Installation & Imports\n",
    "\n",
    "Run each cell sequentially. Start by installing dependencies.\n"
   ],
   "id": "160db7805303f51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:44:07.395072Z",
     "start_time": "2025-11-30T21:44:05.991153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install SpeechRecognition pyaudio pydub pocketsphinx vosk ipywidgets\n",
    "\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"Speech Recognition version: {sr.__version__}\")\n"
   ],
   "id": "b207b7ff040a91db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (3.14.4)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: pydub in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: pocketsphinx in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (5.0.4)\n",
      "Requirement already satisfied: vosk in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (0.3.45)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (8.1.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from SpeechRecognition) (4.15.0)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from SpeechRecognition) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from SpeechRecognition) (0.2.2)\n",
      "Requirement already satisfied: sounddevice in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from pocketsphinx) (0.5.3)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from vosk) (2.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from vosk) (2.32.5)\n",
      "Requirement already satisfied: srt in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from vosk) (3.5.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from vosk) (4.67.1)\n",
      "Requirement already satisfied: websockets in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from vosk) (15.0.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipywidgets) (9.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: pycparser in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from cffi>=1.0->vosk) (2.23)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from requests->vosk) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from requests->vosk) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from requests->vosk) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from requests->vosk) (2025.11.12)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\simon\\pycharmprojects\\jupyterproject\\.venv\\lib\\site-packages (from standard-aifc->SpeechRecognition) (3.13.0)\n",
      "‚úì Imports successful\n",
      "Speech Recognition version: 3.14.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find platform independent libraries <prefix>\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 2: Configuration Setup\n",
    "\n",
    "Configure your speech recognition settings\n"
   ],
   "id": "906e2e9b31ef5423"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:44:07.405884Z",
     "start_time": "2025-11-30T21:44:07.402372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Available Vosk models\n",
    "VOSK_MODELS = {\n",
    "    'english_small': {\n",
    "        'url': 'https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip',\n",
    "        'name': 'vosk-model-small-en-us-0.15',\n",
    "        'size': '40 MB',\n",
    "        'language': 'English (US)'\n",
    "    },\n",
    "    'english_large': {\n",
    "        'url': 'https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip',\n",
    "        'name': 'vosk-model-en-us-0.22',\n",
    "        'size': '1.8 GB',\n",
    "        'language': 'English (US)'\n",
    "    },\n",
    "    'french_small': {\n",
    "        'url': 'https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip',\n",
    "        'name': 'vosk-model-small-fr-0.22',\n",
    "        'size': '41 MB',\n",
    "        'language': 'French'\n",
    "    },\n",
    "    'french': {\n",
    "        'url': 'https://alphacephei.com/vosk/models/vosk-model-fr-0.22.zip',\n",
    "        'name': 'vosk-model-fr-0.22',\n",
    "        'size': '1.5 GB',\n",
    "        'language': 'French'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Global state\n",
    "class Config:\n",
    "    engine = 'sphinx'\n",
    "    vosk_model = None\n",
    "    vosk_model_name = 'french_small'\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(\"‚úì Configuration loaded\")"
   ],
   "id": "5839231ad6e40d47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 3: Interactive Engine Selection\n",
    "\n",
    "Select your speech recognition engine\n"
   ],
   "id": "66ed0c7f6037ba44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:03:46.696375Z",
     "start_time": "2025-11-30T22:03:46.674543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create widgets\n",
    "engine_selector = widgets.RadioButtons(\n",
    "    options=[\n",
    "        ('CMU Sphinx (Built-in, no download needed)', 'sphinx'),\n",
    "        ('Vosk (Better accuracy, requires model download)', 'vosk')\n",
    "    ],\n",
    "    value='sphinx',\n",
    "    description='Engine:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "vosk_model_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('üá¨üáß English Small - 40 MB', 'english_small'),\n",
    "        ('üá¨üáß English Large - 1.8 GB (best accuracy)', 'english_large'),\n",
    "        ('üá´üá∑ French Small - 41 MB', 'french_small'),\n",
    "        ('üá´üá∑ French Large - 1.5 GB (best accuracy)', 'french')\n",
    "    ],\n",
    "    value='french_small',\n",
    "    description='Vosk Model:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px'),\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "status_output = widgets.Output()\n",
    "apply_btn = widgets.Button(\n",
    "    description='Apply & Load Model',\n",
    "    button_style='success',\n",
    "    icon='check',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "# Widget interactions\n",
    "def on_engine_change(change):\n",
    "    vosk_model_selector.disabled = (change['new'] == 'sphinx')\n",
    "\n",
    "def download_and_extract_model(model_info, model_path):\n",
    "    \"\"\"Download and extract Vosk model\"\"\"\n",
    "    import urllib.request\n",
    "    import zipfile\n",
    "    import shutil\n",
    "\n",
    "    zip_filename = f\"{model_info['name']}.zip\"\n",
    "\n",
    "    print(f\"\\nüì• Downloading {model_info['name']}...\")\n",
    "    print(f\"   Size: {model_info['size']} - This may take a while...\")\n",
    "\n",
    "    try:\n",
    "        # Download with progress\n",
    "        def download_progress(block_num, block_size, total_size):\n",
    "            downloaded = block_num * block_size\n",
    "            percent = min(downloaded * 100 / total_size, 100)\n",
    "            print(f\"\\r   Progress: {percent:.1f}%\", end='')\n",
    "\n",
    "        urllib.request.urlretrieve(\n",
    "            model_info['url'],\n",
    "            zip_filename,\n",
    "            reporthook=download_progress\n",
    "        )\n",
    "        print(\"\\n‚úì Download complete!\")\n",
    "\n",
    "        # Extract\n",
    "        print(f\"\\nüì¶ Extracting {zip_filename}...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(\"‚úì Extraction complete!\")\n",
    "\n",
    "        # Clean up zip file\n",
    "        os.remove(zip_filename)\n",
    "        print(\"‚úì Cleanup complete!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Download/extraction failed: {e}\")\n",
    "        if os.path.exists(zip_filename):\n",
    "            os.remove(zip_filename)\n",
    "        return False\n",
    "\n",
    "def on_apply_click(b):\n",
    "    config.engine = engine_selector.value\n",
    "    config.vosk_model_name = vosk_model_selector.value\n",
    "\n",
    "    with status_output:\n",
    "        clear_output()\n",
    "        print(f\"‚úì Engine set to: {config.engine.upper()}\")\n",
    "\n",
    "        if config.engine == 'vosk':\n",
    "            model_info = VOSK_MODELS[config.vosk_model_name]\n",
    "            print(f\"\\nModel: {model_info['name']}\")\n",
    "            print(f\"Language: {model_info['language']}\")\n",
    "            print(f\"Size: {model_info['size']}\")\n",
    "\n",
    "            try:\n",
    "                from vosk import Model\n",
    "                model_path = Path(model_info['name'])\n",
    "\n",
    "                if not model_path.exists():\n",
    "                    print(f\"\\n‚ö†Ô∏è  Model not found locally!\")\n",
    "                    print(f\"\\nüì• Do you want to download {model_info['name']} ({model_info['size']})?\")\n",
    "\n",
    "                    # Create download buttons\n",
    "                    download_btn = widgets.Button(\n",
    "                        description=f'‚úì Download ({model_info[\"size\"]})',\n",
    "                        button_style='success',\n",
    "                        icon='download'\n",
    "                    )\n",
    "                    cancel_btn = widgets.Button(\n",
    "                        description='‚úó Cancel',\n",
    "                        button_style='danger',\n",
    "                        icon='times'\n",
    "                    )\n",
    "\n",
    "                    button_output = widgets.Output()\n",
    "\n",
    "                    def on_download(b):\n",
    "                        with button_output:\n",
    "                            clear_output()\n",
    "                            if download_and_extract_model(model_info, model_path):\n",
    "                                print(f\"\\n‚è≥ Loading model...\")\n",
    "                                config.vosk_model = Model(str(model_path))\n",
    "                                print(f\"‚úì Model loaded successfully!\")\n",
    "                            else:\n",
    "                                print(\"\\n‚ùå Failed to download model. Please try manual download:\")\n",
    "                                print(f\"   wget {model_info['url']}\")\n",
    "                                print(f\"   unzip {model_info['name']}.zip\")\n",
    "                                config.vosk_model = None\n",
    "\n",
    "                    def on_cancel(b):\n",
    "                        with button_output:\n",
    "                            clear_output()\n",
    "                            print(\"\\n‚ùå Download cancelled.\")\n",
    "                            print(f\"\\nManual download instructions:\")\n",
    "                            print(f\"   wget {model_info['url']}\")\n",
    "                            print(f\"   unzip {model_info['name']}.zip\")\n",
    "                            print(f\"\\nOr download from: {model_info['url']}\")\n",
    "                            config.vosk_model = None\n",
    "\n",
    "                    download_btn.on_click(on_download)\n",
    "                    cancel_btn.on_click(on_cancel)\n",
    "\n",
    "                    display(widgets.HBox([download_btn, cancel_btn]))\n",
    "                    display(button_output)\n",
    "\n",
    "                else:\n",
    "                    print(f\"\\n‚è≥ Loading model...\")\n",
    "                    config.vosk_model = Model(str(model_path))\n",
    "                    print(f\"‚úì Model loaded successfully!\")\n",
    "\n",
    "            except ImportError:\n",
    "                print(f\"\\n‚ö†Ô∏è  Vosk not installed!\")\n",
    "                print(f\"Run: !pip install vosk\")\n",
    "                config.vosk_model = None\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Error: {e}\")\n",
    "                config.vosk_model = None\n",
    "        else:\n",
    "            print(\"\\n‚úì Using CMU Sphinx (built-in)\")\n",
    "            print(\"No additional download needed!\")\n",
    "\n",
    "engine_selector.observe(on_engine_change, names='value')\n",
    "apply_btn.on_click(on_apply_click)\n",
    "\n",
    "# Display\n",
    "display(HTML(\"<h3>üé§ Speech Recognition Configuration</h3>\"))\n",
    "display(widgets.VBox([\n",
    "    engine_selector,\n",
    "    vosk_model_selector,\n",
    "    apply_btn,\n",
    "    status_output\n",
    "]))"
   ],
   "id": "9fe36ff121a7d678",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<h3>üé§ Speech Recognition Configuration</h3>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(RadioButtons(description='Engine:', layout=Layout(width='500px'), options=(('CMU Sphinx (Built-‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9f5c8cc68494832ac1e48196aa758e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 4: Helper Functions\n",
    "\n",
    "Core recognition functions"
   ],
   "id": "68435ef1c21a6296"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:13:21.693319Z",
     "start_time": "2025-11-30T22:13:21.687749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recognize_audio(audio_data):\n",
    "    \"\"\"Recognize speech using the configured engine\"\"\"\n",
    "\n",
    "    if config.engine == 'sphinx':\n",
    "        try:\n",
    "            return config.recognizer.recognize_sphinx(audio_data)\n",
    "        except sr.UnknownValueError:\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Sphinx error: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif config.engine == 'vosk':\n",
    "        if config.vosk_model is None:\n",
    "            print(\"‚ö†Ô∏è  Vosk model not loaded. Please configure and load a model first.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            from vosk import KaldiRecognizer\n",
    "            import io\n",
    "            import wave\n",
    "\n",
    "            # Get raw audio data\n",
    "            wav_data = audio_data.get_wav_data()\n",
    "\n",
    "            # Read the WAV data to get actual sample rate\n",
    "            with io.BytesIO(wav_data) as wav_io:\n",
    "                with wave.open(wav_io, 'rb') as wf:\n",
    "                    sample_rate = wf.getframerate()\n",
    "                    frames = wf.readframes(wf.getnframes())\n",
    "\n",
    "            # Create recognizer with the correct sample rate\n",
    "            rec = KaldiRecognizer(config.vosk_model, sample_rate)\n",
    "            rec.SetWords(True)\n",
    "\n",
    "            # Process the audio data\n",
    "            rec.AcceptWaveform(frames)\n",
    "            result = json.loads(rec.FinalResult())\n",
    "\n",
    "            text = result.get('text', '').strip()\n",
    "\n",
    "            # Debug: show what Vosk actually returned\n",
    "            if not text:\n",
    "                print(f\"Debug: Vosk result = {result}\")\n",
    "\n",
    "            return text if text else None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Vosk error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "def configure_recognizer():\n",
    "    \"\"\"Optimize recognizer settings\"\"\"\n",
    "    config.recognizer.energy_threshold = 4000\n",
    "    config.recognizer.dynamic_energy_threshold = True\n",
    "    config.recognizer.dynamic_energy_adjustment_damping = 0.15\n",
    "    config.recognizer.dynamic_energy_ratio = 1.5\n",
    "    config.recognizer.pause_threshold = 0.8\n",
    "    config.recognizer.phrase_threshold = 0.3\n",
    "    config.recognizer.non_speaking_duration = 0.5\n",
    "\n",
    "print(\"‚úì Helper functions loaded\")"
   ],
   "id": "10471cfd3fab6135",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Helper functions loaded\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 5: List Available Microphones\n",
    "\n",
    "Check your available audio input devices\n"
   ],
   "id": "c6a42c8c83cdebc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:44:07.567145Z",
     "start_time": "2025-11-30T21:44:07.459295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Check your available audio input devices\n",
    "\"\"\"\n",
    "\n",
    "def list_microphones():\n",
    "    print(\"Available microphones:\")\n",
    "    for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "        print(f\"  {index}: {name}\")\n",
    "\n",
    "# Run this to see your microphones\n",
    "list_microphones()"
   ],
   "id": "c8cfe225f9655171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available microphones:\n",
      "  0: Mappeur de sons Microsoft - Input\n",
      "  1: R√É¬©seau de microphones (Realtek(\n",
      "  2: Casque (PowerLocus)\n",
      "  3: Mappeur de sons Microsoft - Output\n",
      "  4: Casque (PowerLocus)\n",
      "  5: Haut-parleurs (Realtek(R) Audio\n",
      "  6: Pilote de capture audio principal\n",
      "  7: R√É¬©seau de microphones (Realtek(R) Audio)\n",
      "  8: Casque (PowerLocus)\n",
      "  9: P√É¬©riph√É¬©rique audio principal\n",
      "  10: Casque (PowerLocus)\n",
      "  11: Haut-parleurs (Realtek(R) Audio)\n",
      "  12: Haut-parleurs (Realtek(R) Audio)\n",
      "  13: Casque (PowerLocus)\n",
      "  14: Casque (PowerLocus)\n",
      "  15: R√É¬©seau de microphones (Realtek(R) Audio)\n",
      "  16: Casque ()\n",
      "  17: Speakers (Nahimic Wave Speaker)\n",
      "  18: R√É¬©seau de microphones (Realtek HD Audio Mic Array input)\n",
      "  19: Headphones 1 (Realtek HD Audio 2nd output with SST)\n",
      "  20: Headphones 2 (Realtek HD Audio 2nd output with SST)\n",
      "  21: Haut-parleur du PC (Realtek HD Audio 2nd output with SST)\n",
      "  22: Mixage st√É¬©r√É¬©o (Realtek HD Audio Stereo input)\n",
      "  23: Microphone (Realtek HD Audio Mic input)\n",
      "  24: Speakers 1 (Realtek HD Audio output with SST)\n",
      "  25: Speakers 2 (Realtek HD Audio output with SST)\n",
      "  26: Haut-parleur du PC (Realtek HD Audio output with SST)\n",
      "  27: Casque (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\r\n",
      ";(PowerLocus))\n",
      "  28: Casque (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\r\n",
      ";(PowerLocus))\n",
      "  29: Casque ()\n",
      "  30: Speakers (Nahimic mirroring Wave Speaker)\n",
      "  31: Casque (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\r\n",
      ";(COLORBUDS))\n",
      "  32: Casque (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\r\n",
      ";(COLORBUDS))\n",
      "  33: Speakers (Nahimic Easy Surround)\n",
      "  34: Casque ()\n",
      "  35: Casque (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\r\n",
      ";(MAJOR IV))\n",
      "  36: Casque (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\r\n",
      ";(MAJOR IV))\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 6: Single Recognition Test\n",
    "Test recognition with a single phrase\n",
    "Run this cell and speak when prompted"
   ],
   "id": "3df7669f150d2a07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:14:00.691517Z",
     "start_time": "2025-11-30T22:13:54.513583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_single_recognition():\n",
    "    print(f\"Using engine: {config.engine.upper()}\")\n",
    "\n",
    "    if config.engine == 'vosk' and config.vosk_model is None:\n",
    "        print(\"‚ö†Ô∏è  Please load a Vosk model first (Cell 3)\")\n",
    "        return\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"\\n‚è≥ Adjusting for ambient noise...\")\n",
    "        config.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "\n",
    "        print(\"üé§ Listening... Speak now!\")\n",
    "        audio = config.recognizer.listen(source, timeout=5, phrase_time_limit=10)\n",
    "\n",
    "        print(\"‚è≥ Processing...\")\n",
    "        text = recognize_audio(audio)\n",
    "\n",
    "        if text:\n",
    "            print(f\"\\n‚úì Recognized: '{text}'\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå Could not understand the audio\")\n",
    "\n",
    "test_single_recognition()"
   ],
   "id": "96d82deb90f42774",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using engine: VOSK\n",
      "\n",
      "‚è≥ Adjusting for ambient noise...\n",
      "üé§ Listening... Speak now!\n",
      "‚è≥ Processing...\n",
      "\n",
      "‚úì Recognized: 'test'\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 7: Continuous Listening Mode\n",
    "Continuous speech recognition\n",
    "Press the stop button (‚ñ†) to interrupt"
   ],
   "id": "199435d8c859fb70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:15:03.395503Z",
     "start_time": "2025-11-30T22:14:30.837267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def start_continuous_listening():\n",
    "    print(f\"=== Continuous Listening ({config.engine.upper()}) ===\")\n",
    "\n",
    "    if config.engine == 'vosk' and config.vosk_model is None:\n",
    "        print(\"‚ö†Ô∏è  Please load a Vosk model first (Cell 3)\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüé§ Speak clearly into your microphone\")\n",
    "    print(\"üõë Press the stop button (‚ñ†) to exit\\n\")\n",
    "\n",
    "    configure_recognizer()\n",
    "\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"‚è≥ Adjusting for ambient noise...\")\n",
    "            config.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            print(\"‚úì Ready! Start speaking...\\n\")\n",
    "\n",
    "            phrase_count = 0\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    print(f\"[Listening for phrase #{phrase_count + 1}...]\")\n",
    "                    audio = config.recognizer.listen(source, timeout=None, phrase_time_limit=10)\n",
    "\n",
    "                    print(\"‚è≥ Processing...\")\n",
    "                    text = recognize_audio(audio)\n",
    "\n",
    "                    if text:\n",
    "                        phrase_count += 1\n",
    "                        print(f\"‚úì Phrase #{phrase_count}: '{text}'\\n\")\n",
    "                    else:\n",
    "                        print(\"‚ùå Could not understand audio\\n\")\n",
    "\n",
    "                except KeyboardInterrupt:\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error: {e}\\n\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    print(f\"\\nüõë Stopped. Total phrases recognized: {phrase_count}\")\n",
    "\n",
    "start_continuous_listening()"
   ],
   "id": "88fa0370bc8da655",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Continuous Listening (VOSK) ===\n",
      "\n",
      "üé§ Speak clearly into your microphone\n",
      "üõë Press the stop button (‚ñ†) to exit\n",
      "\n",
      "‚è≥ Adjusting for ambient noise...\n",
      "‚úì Ready! Start speaking...\n",
      "\n",
      "[Listening for phrase #1...]\n",
      "‚è≥ Processing...\n",
      "‚úì Phrase #1: 'est un test en continu'\n",
      "\n",
      "[Listening for phrase #2...]\n",
      "‚è≥ Processing...\n",
      "‚úì Phrase #2: 'si je tente de parler que me diras-tu'\n",
      "\n",
      "[Listening for phrase #3...]\n",
      "‚è≥ Processing...\n",
      "‚úì Phrase #3: 'peut-√™tre que tu nous diras que j'ai fa√ßon'\n",
      "\n",
      "[Listening for phrase #4...]\n",
      "‚è≥ Processing...\n",
      "‚úì Phrase #4: 'peut-√™tre que tu diras des conneries'\n",
      "\n",
      "[Listening for phrase #5...]\n",
      "\n",
      "üõë Stopped. Total phrases recognized: 4\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 8: Recognize from Audio File\n",
    "Transcribe an existing audio file\n",
    "Supports: WAV, AIFF, FLAC"
   ],
   "id": "a220373407e9df02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:44:07.603033Z",
     "start_time": "2025-11-30T21:44:07.598756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recognize_from_file(audio_file_path):\n",
    "    if not os.path.exists(audio_file_path):\n",
    "        print(f\"‚ùå File not found: {audio_file_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Using engine: {config.engine.upper()}\")\n",
    "\n",
    "    if config.engine == 'vosk' and config.vosk_model is None:\n",
    "        print(\"‚ö†Ô∏è  Please load a Vosk model first (Cell 3)\")\n",
    "        return None\n",
    "\n",
    "    with sr.AudioFile(audio_file_path) as source:\n",
    "        print(f\"‚è≥ Loading audio from {audio_file_path}...\")\n",
    "        audio = config.recognizer.record(source)\n",
    "\n",
    "        print(\"‚è≥ Processing...\")\n",
    "        text = recognize_audio(audio)\n",
    "\n",
    "        if text:\n",
    "            print(f\"\\n‚úì Recognized: '{text}'\")\n",
    "            return text\n",
    "        else:\n",
    "            print(\"\\n‚ùå Could not understand the audio\")\n",
    "            return None\n",
    "\n",
    "# Example usage:\n",
    "# recognize_from_file(\"your_audio_file.wav\")"
   ],
   "id": "7b44bc5224cd4a92",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 9: Create Test Recording\n",
    "Record audio to a file for testing"
   ],
   "id": "3b5fbf72aac36209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:44:07.610190Z",
     "start_time": "2025-11-30T21:44:07.607393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_test_recording(filename=\"test_recording.wav\", duration=5):\n",
    "    with sr.Microphone() as source:\n",
    "        print(f\"üî¥ Recording for {duration} seconds...\")\n",
    "        config.recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = config.recognizer.listen(source, timeout=duration, phrase_time_limit=duration)\n",
    "\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "\n",
    "        print(f\"‚úì Recording saved to {filename}\")\n",
    "        return filename\n",
    "\n",
    "# Uncomment to run:\n",
    "# create_test_recording()"
   ],
   "id": "ac413e2810f441ea",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
